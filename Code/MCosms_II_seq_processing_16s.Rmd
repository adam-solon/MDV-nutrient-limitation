---
title: "Nutrient Limitation in the MDV of Antarctica"
subtitle: "  \n Processing of Amplicon Sequence Variants - 16S SSU rRNA gene"
author: "Adam J. Solon"
date: "`r Sys.Date()`"
#output: html_document
output: 
  pdf_document:
    #includes:  
     # in_header: my_header.txt
    toc: TRUE
    fig_width: 8
    fig_height: 6
    fig_caption: true
fontsize: 12pt
#editor_options: 
#  chunk_output_type: console
---

# Script Summary  
This script processes the Amplicon Sequence Variants (ASVs) table output from DADA2. It subsets ASVs from a nutrient limitation study of soils of the McMurdo Dry Valleys, then subsets that study into into three separate groupings based on geography- enclosed lake basins of Taylor ValleyBonney, Hoare, and Fryxell. 

### Steps of this pipeline:  
1.  Create and organize directories
2.  Load R packages
3.  Input files
4.  Format Files
5.  Subset according to study
6.  Subset accoring to basin  
  
```{r echo = FALSE, include = FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(include = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)

```
  
```{r, echo = FALSE, include = FALSE}
# Change identifiers to your system and file naming. 
user <- "C:/Users/adams" # computer user name
folder <- "/Desktop/Projects"
project <- "/MDV_Soils_nutrient_limitation/manuscript1"
analyses <- "/analyses"
data  <- "/dna_seq/amplicons"
analysis1 <- "/seq_processing/16S"
analysis2 <- "/RA_relative_abundance/16S"
ecosystem <- "lab microcosms - Taylor Valley soils" # Define the environment for use in report language.
project.fp <- paste0(user, folder, project)

```
  
### Set pathways and create directories  
  
```{r set paths for project}
# First define the project and project folders. 

# Create project directory
###################################################
project.fp <- paste0(user, folder, project)
if (!dir.exists(project.fp)) dir.create(project.fp)

# Create sub-directory for all analyses for project 
###################################################
analyses.fp <- paste0(project.fp, analyses)
if (!dir.exists(analyses.fp)) dir.create(analyses.fp)

# Create sub-directory for data type 
###################################################
data.fp <- paste0(analyses.fp, data)
if (!dir.exists(data.fp)) dir.create(data.fp)

# Create sub-directory for specific analysis 
###################################################
analysis1.fp <- paste0(data.fp, analysis1)
if (!dir.exists(analysis1.fp)) dir.create(analysis1.fp)

# Create sub-directories for analysis 
###################################################

# Create directory for 'before' pipeline inputs
input.fp <- paste0(analysis1.fp, "/input")
if (!dir.exists(input.fp)) dir.create(input.fp)

# Create directory for 'within' pipeline R objects 
objects.fp <- paste0(analysis1.fp, "/objects")
if (!dir.exists(objects.fp)) dir.create(objects.fp)

# Create directory for 'after' pipeline outputs 
output.fp <- paste0(analysis1.fp, "/output")
if (!dir.exists(output.fp)) dir.create(output.fp)

# Check for the folders here as a sanity check. Should see "Input" and "Objects" if starting from scratch.
list.files(analysis1.fp) 
```
  
```{r}
# Create sub-directory for Relative Abundance (RA) analysis
###################################################
analysis2.fp <- paste0(data.fp, analysis2)
if (!dir.exists(analysis2.fp)) dir.create(analysis2.fp)

# Create sub-directories for RA 
###################################################

# Create directory for 'before' pipeline inputs
input2.fp <- paste0(analysis2.fp, "/input")
if (!dir.exists(input2.fp)) dir.create(input2.fp)

# Create directory for 'within' pipeline R objects 
objects2.fp <- paste0(analysis2.fp, "/objects")
if (!dir.exists(objects2.fp)) dir.create(objects2.fp)

# Create directory for 'after' pipeline outputs 
output2.fp <- paste0(analysis2.fp, "/output")
if (!dir.exists(output2.fp)) dir.create(output2.fp)

# Check for the folders here as a sanity check. Should see "Input" and "Objects" if starting from scratch.
list.files(analysis2.fp) 

```
  
```{r}
# Create further sub-directories by basin
###################################################

# Create directory for 'within' pipeline R objects 
objects2.b.fp <- paste0(objects2.fp, "/bonney")
if (!dir.exists(objects2.b.fp)) dir.create(objects2.b.fp)

# Create directory for 'after' pipeline outputs 
output2.b.fp <- paste0(output2.fp, "/bonney")
if (!dir.exists(output2.b.fp)) dir.create(output2.b.fp)

# Create sub-directories for Hoare basin 
###################################################

# Create directory for 'within' pipeline R objects 
objects2.h.fp <- paste0(objects2.fp, "/hoare")
if (!dir.exists(objects2.h.fp)) dir.create(objects2.h.fp)

# Create directory for 'after' pipeline outputs 
output2.h.fp <- paste0(output2.fp, "/hoare")
if (!dir.exists(output2.h.fp)) dir.create(output2.h.fp)

# Create sub-directories for Fryxell basin 
###################################################

# Create directory for 'within' pipeline R objects 
objects2.f.fp <- paste0(objects2.fp, "/fryxell")
if (!dir.exists(objects2.f.fp)) dir.create(objects2.f.fp)

# Create directory for 'after' pipeline outputs 
output2.f.fp <- paste0(output2.fp, "/fryxell")
if (!dir.exists(output2.f.fp)) dir.create(output2.f.fp)

```
  
### Load R packages  
  
```{r Install and load packages, echo = FALSE, include = FALSE}

# install.packages("tidyverse")
# install.packages("knitr")
# install.packages("kableExtra")
# install.packages("stringr")

library(tidyverse); packageVersion("tidyverse")
library(knitr); packageVersion("knitr")
library(kableExtra); packageVersion("kableExtra")
library(stringr); packageVersion("stringr")

```
  
* r version: `r getRversion()`
* RStudio version: `r rstudioapi::versionInfo()$version`
* r packages:  
  tidyverse, `r packageVersion("tidyverse")` 
  knitr, `r packageVersion("knitr")`  
  kableExtra, `r packageVersion("KableExtra")`  
  stringr, `r packageVersion("stringr")`  
  
### Input Files
Required input files:   
  
1.  The ASV table from DADA2 pipeline 
2.  The 'mapping file' w/ relevant metadata for each sample

Input files and re-format for use in pipeline  
  
```{r input data files}
# input data files
# ASV Table (from DADA2)
asvTable.fp <- paste0(input.fp, "/MCosms_II_seqtab_wTax_16s.txt") 

# Mapping File (metadata relevant for study samples)
mappingFile.fp <- paste0(input.fp, "/MCosms_II_map_file.txt") 

#input 16s ASV table w/ taxonomy
a <- read.table(asvTable.fp, header = T, sep = "\t")

#input metadata (i.e. mapping file)
m <- read.table(mappingFile.fp, header = T, sep = "\t")
#

```
  
### Format Files

```{r format}
#rename 'ESV_ID' column in ASV table and remove 'taxonomy' from ASV table and create separate taxonomy data frame
#rename ESV_ID
a <- rename(a, ASV_ID = ESV_ID)

#create data frame of only taxonomy
t <- as.data.frame(a$taxonomy)

#ASV IDs as row names
rownames(t) <- a$ASV_ID

#rename column as 'taxonomy'
names(t)[1] <- "taxonomy"

#move row names to 1st column and name 'ASV_ID'
t <- tibble::rownames_to_column(t, "ASV_ID")

#separate the taxonomic string by the ; separator
t.1 <- str_split_fixed(t$taxonomy, ";", 7)

#rename columns w/ taxonomic ranks for 16S data
colnames(t.1)[1:7] <- c("Domain", "Phylum", "Class", "Order", "Family", "Genus", "ASV_ID")

#save t.1 object as data frame
t.1 <- as.data.frame(t.1)

#remove 'taxonomy' column from ASV table
a$taxonomy <- NULL
```
  
### Subset by MDV nutrient limitation study  
  
```{r subset samples}
#subset ASV table
#assign row names from 'ASV_ID' column
rownames(a) <- a$ASV_ID

#remove ESV_ID column
a$ASV_ID <- NULL

#transpose so rows and columns are flipped
a.1 <- as.data.frame(t(a))

#move row names of samples into 1st column as 'SampleID' to match 1st column of mapping file
a.1 <- tibble::rownames_to_column(a.1, "SampleID")

#keep rows in ASV table with SampleIDs that match Sample IDs in mapping file
a.2 <- subset(a.1, (SampleID %in% m$SampleID )) 

#assign samples IDs back as row names
rownames(a.2) <- a.2$SampleID

#remove Sample ID column
a.2$SampleID <- NULL

```
  
### Remove ASVs not present in this study  
  
```{r}
#transpose
a.3 <- as.data.frame(t(a.2))

# create row sum column for ASV total sequences
a.3 <- a.3 %>% mutate(total = rowSums(.))

# re-order with greatest row sum 1st
a.3 <- a.3 %>% arrange(desc(total))

#remove rows (i.e., ASVs) that contain zeros
a.4 <- a.3 %>% filter(total!= 0)

#remove 'total' column
a.4$total <- NULL

```
  
### Subset blanks to remove possible contaminants  
This step will subset out blank samples to determine if any contaminants were introduced during post-experiment sample processing (e.g., DNA extraction, library prep, sequencing).  
  
```{r create a data frame with blanks to determine contaminants in other samples}

#subset mapping file with only blanks
m.blanks <- filter(m, location == "Blank") 

#transpose
a.5 <- as.data.frame(t(a.4))

#move row names of samples into 1st column as 'SampleID' to match 1st column of mapping file
a.5 <- tibble::rownames_to_column(a.5, "SampleID")

#keep rows in ASV table with SampleIDs that match Sample IDs in mapping file
a.blanks <- subset(a.5, (SampleID %in% m.blanks$SampleID )) 

#set sampleIDs as rownames
rownames(a.blanks) <- a.blanks$SampleID

#remove 'SampleID' column
a.blanks$SampleID <- NULL

#transpose
a.blanks.1 <- as.data.frame(t(a.blanks))

# create row sum column for ASV total sequences
a.blanks.1 <- a.blanks.1 %>% mutate(total = rowSums(.))

# re-order with greatest row sum 1st
a.blanks.1 <- a.blanks.1 %>% arrange(desc(total))

#remove rows (i.e., ASVs) that contain zeros
a.blanks.2 <- a.blanks.1 %>% filter(total!= 0)

#move row names of samples into 1st column as 'SampleID' to match column in taxonomy file
a.blanks.2 <- tibble::rownames_to_column(a.blanks.2, "ASV_ID")

#add taxonomy columns back into ASV table with a Left Join using inner_join function from dplyr
a.blanks.T <- a.blanks.2 %>% inner_join(t.1, by= "ASV_ID")

```

```{r}
print(a.blanks.T)
```
  
### Evaluate possible contamination  
The high number sequences for some ESVs in B225 are likely reverse contamination (i.e. dna material from the samples were introduced into the blanks).  This is due to blanks reprsenting different extraction runs revealing consistenly high numbers of certain ESVs from bulk soils (e.g. ESV 1, ESV 2) but either zero or high numbers in the blanks from those different extraction runs.  Due to this circumstance, ESVs that are present in B225 will be considered contaminants only if they are not in seen consistently across samples from different extraction runs.  

```{r}
#remove column with B225 values
a.blanks.T.1 <- a.blanks.T %>% select(!B225)

#recalculate total values
# create row sum column for ASV total sequences
a.blanks.T.1 <- a.blanks.T.1 %>% mutate(total = rowSums(.[2:8]))

# re-order with greatest row sum 1st
a.blanks.T.1 <- a.blanks.T.1 %>% arrange(desc(total))

#remove rows (i.e., ASVs) that contain zeros
a.blanks.T.2 <- a.blanks.T.1 %>% filter(total!= 0)

```
  
```{r kable 1, include = TRUE}
#create table of library size align = "lcccccccc", 
knitr::kable(a.blanks.T.2, booktabs = T, digits = 2, caption = 'ESVs that are present in blank extractions - possible contaminanation') %>%
  kable_styling(latex_options = c("striped", "scale_down", "hold_position")) %>%
  row_spec(0, bold = T)

```
  
### Save contaminant list  
  
```{r}
# save as an R file
saveRDS(a.blanks.T.2, paste0(objects.fp, "/a.blanks.T.2.rds"))

#save as .txt file
write.table(a.blanks.T.2, file = paste0(output.fp, "/asvTab_blanks_wTax.txt"), 
            sep = "\t", row.names = TRUE, col.names = NA)

```
  
### Calculate library size of each sample before filtering 
  
```{r create new column with row sums (i.e. library size of each sample) and reorder rows by descending value}

#keep rows in ASV table with SampleIDs that do NOT match Sample IDs in blanks mapping file
a.6 <- subset(a.5, !(SampleID %in% m.blanks$SampleID )) 

#row names as SampleID column
rownames(a.6) <- a.6$SampleID

#remove 'SampleID' column
a.6$SampleID <- NULL

# create row sum column
a.lib.size <- a.6 %>% mutate(library_size = rowSums(.))

# re-order with greatest row sum 1st
a.lib.size <- a.lib.size %>% arrange(desc(library_size))

#remove any samples with less than 1000 sequences
a.lib.size.1 <- a.lib.size %>% filter(library_size > 1000)

#class data frame 
a.lib.size.2 <- as.data.frame(a.lib.size.1$library_size)

#ASV IDs as row names
rownames(a.lib.size.2) <- rownames(a.lib.size.1)

#rename column as 'taxonomy'
names(a.lib.size.2)[1] <- "Library_Size"

#move row names to 1st column and name 'ASV_ID'
a.lib.size.2 <- tibble::rownames_to_column(a.lib.size.2, "SampleID")

#add row with total sequences of study
a.lib.size.2 <- a.lib.size.2 %>%
            bind_rows(summarise(., across(where(is.numeric), sum),
                                   across(where(is.character), ~'Total')))

# save as an R file
saveRDS(a.lib.size.2, paste0(objects.fp, "/a.lib.size.2.rds"))

#save as .txt file
write.table(a.lib.size.2, file = paste0(output.fp, "/asvTab_library_size.txt"), 
            sep = "\t", row.names = FALSE, col.names = TRUE)

```
  
### Remove contaminants  
  
```{r}

#remove only ASVs from blanks table with sufficient sequence amounts (e.g. 50 sequences)
c <- a.blanks.T.2 %>% filter(total > 50)

#transpose ASV talbe back to samples as columns and ASVs as rows
a.7 <- as.data.frame(t(a.6))

#move row names of samples into 1st column as 'SampleID' to match column in taxonomy file
a.7 <- tibble::rownames_to_column(a.7, "ASV_ID")

#remove rows with ESVID that matches contaminant column of ESVIS
a.8 <- subset(a.7, !(ASV_ID %in% c$ASV_ID)) 

```
  
### Filter for incorrect taxonomic assignment (e.g. eukaryotes)
  
```{r}
#add taxonomy columns back into ASV table with a Left Join using inner_join function from dplyr
a.8.T <- a.8 %>% inner_join(t.1, by= "ASV_ID")

#remove ASVs that are completely unassigned
a.9 <- a.8.T %>% filter(Domain != c("NA")) 

#remove ASVs that are eukaryotes (because these are 16S-amplified libraries NOT 18S) 
a.10 <- a.9 %>% filter(Domain != c("Eukaryota")) 

#remove chloroplast that are identified as cyanobacteria
a.11 <- a.10 %>% filter(Order != "Chloroplast")

#remove mitochondria that are identified as alphaproteobacteria
a.12 <- a.11 %>% filter(Family != "Mitochondria")

# save as an R file
saveRDS(a.12, paste0(objects.fp, "/ASV.table.12.wTax.filtered.rds"))

#save as .txt file
write.table(a.12, file = paste0(output.fp, "/asvTab_16S_wTax_filtered.txt"), 
            sep = "\t", row.names = FALSE, col.names = TRUE)

```
  
### Save ASV table and mapping file without blanks  
  
```{r create new sub-directories for additional analyses}
# save as an R file
saveRDS(a.12, paste0(objects2.fp, "/ASV.table.12.wTax.filtered.rds"))

#save as .txt file
write.table(a.12, file = paste0(input2.fp, "/asvTab_16S_wTax_filtered.txt"), 
            sep = "\t", row.names = FALSE, col.names = TRUE)

#subset mapping file without blanks
m.1 <- filter(m, treatment != "blank") 

# save mapping file subset as an R file
saveRDS(m.1, paste0(objects2.fp, "/m.1.rds"))

#save mapping file subset as .txt file 
write.table(m.1, file = paste0(input2.fp, "/map_file_no_blanks.txt"), 
            sep = "\t", row.names = FALSE, col.names = TRUE)

```
  
### Format ASV table for further processing  
  
```{r}

#row names as SampleID column
rownames(a.12) <- a.12$ASV_ID

#remove 'SampleID' column
a.12$ASV_ID <- NULL

#remove taxonomy columns
a.13 <- subset (a.12, select = -c(Domain:Genus))

#transpose
a.13 <- data.frame(t(a.13))
```
  
### Calculate library size of each sample after filtering
  
```{r}

# create row sum column
a.lib.size.filt <- a.13 %>% mutate(library_size = rowSums(.))

# re-order with greatest row sum 1st
a.lib.size.filt <- a.lib.size.filt %>% arrange(desc(library_size))

#class data frame 
a.lib.size.filt.1 <- as.data.frame(a.lib.size.filt$library_size)

#ASV IDs as row names
rownames(a.lib.size.filt.1) <- rownames(a.lib.size.filt)

#rename column as 'taxonomy'
names(a.lib.size.filt.1)[1] <- "Library_Size_Filtered"

#move row names to 1st column and name 'ASV_ID'
a.lib.size.filt.1 <- tibble::rownames_to_column(a.lib.size.filt.1, "SampleID")

#add row with total sequences of study
a.lib.size.filt.1 <- a.lib.size.filt.1 %>%
            bind_rows(summarise(., across(where(is.numeric), sum),
                                   across(where(is.character), ~'Total')))

# save as an R file
saveRDS(a.lib.size.filt.1, paste0(objects.fp, "/a.lib.size.filt.1.rds"))

#save as .txt file
write.table(a.lib.size.filt.1, file = paste0(output.fp, "/asvTab_library_size_filtered.txt"), 
            sep = "\t", row.names = FALSE, col.names = TRUE)

```
  
### Save library size before and after  
  
```{r}
#add taxonomy columns back into ASV table with a Left Join using inner_join function from dplyr
lib.size.final <- a.lib.size.2 %>% inner_join(a.lib.size.filt.1, by= "SampleID")

# create row sum column
lib.size.final.1 <- lib.size.final %>% mutate(filtered = Library_Size - Library_Size_Filtered)

# save as an R file
saveRDS(lib.size.final.1, paste0(objects.fp, "/lib.size.final.1.rds"))

#save as .txt file
write.table(lib.size.final.1, file = paste0(output.fp, "/Library_Size_final.txt"), 
            sep = "\t", row.names = FALSE, col.names = TRUE)

#visualize filtering
#ggplot(lib.size.final.1, aes(x= , y = SampleID)) + geom_point() # w/ blanks: color=Sample_or_Control

#ggplot(lib.size.final.1) +
#  aes(x = filtered, color = , fill = filtered) +
#  geom_density(alpha = 0.25) # add transparency


```
  
\newpage  
## Library size  
  
```{r kable 2, include = TRUE}
#create table of library size align = "lcccccccc", 
knitr::kable(lib.size.final.1, col.names = c('Sample', 'Before', 'After', 'Removed'), booktabs = T, longtable = T, linesep = "", align = "lccc", caption = 'Library Size- total number of sequences in each sample before and after filtering') %>%
  kable_styling(font_size = 10) %>%
  row_spec(0, bold = T)

```
  
### Subset and save by basin for follow-on analyses  
  
```{r}
# Subset by Basin
##################################################################
# Bonney Basin
##################################################################
#subset mapping file- Bonney
m.bn <- filter(m.1, location == "BonneyBasin") 

#for RA
# save bonney subset as an R file
saveRDS(m.bn, paste0(objects2.b.fp, "/m.bn.rds"))

#save bonney subset as .txt file 
write.table(m.bn, file = paste0(input2.fp, "/map_file_bonney.txt"), 
            sep = "\t", row.names = FALSE, col.names = TRUE)

# Hoare Basin
#################################################################
#subset mapping file- Hoare
m.hr <- filter(m.1, location == "HoareBasin") 

#for RA
#save hoare subset as an R file
saveRDS(m.hr, paste0(objects2.h.fp, "/m.hr.rds"))

#save hoare subset as .txt file
write.table(m.hr, file = paste0(input2.fp, "/map_file_hoare.txt"), 
            sep = "\t", row.names = FALSE, col.names = TRUE)

#Fryxell Basin
###################################################################
#subset mapping file- Fryxell 
m.fx <- filter(m.1, location == "FryxellBasin") 

#for RA
#save fryxell subset as an R file
saveRDS(m.fx, paste0(objects2.f.fp, "/m.fx.rds"))

#save fryxell as .txt file
write.table(m.fx, file = paste0(input2.fp, "/map_file_fryxell.txt"), 
            sep = "\t", row.names = FALSE, col.names = TRUE)

```
  
```{r}

#move row names of samples into 1st column as 'SampleID' to match 1st column of mapping file
a.14 <- tibble::rownames_to_column(a.13, "SampleID")

# Subset by basin
####################################################################
# Bonney Basin
####################################################################
#keep rows in ASV table with SampleIDs that match Sample IDs in mapping file
a.bn <- subset(a.14, (SampleID %in% m.bn$SampleID )) 

#assign rownames as Sample IDs
rownames(a.bn) <- a.bn$SampleID

#remove SampleID column
a.bn$SampleID <- NULL

#transpose
a.bn.1 <- data.frame(t(a.bn))

#merge ASV table and Taxonomy data frame
#move row names of samples into 1st column as 'SampleID' to match column in taxonomy file
a.bn.1 <- tibble::rownames_to_column(a.bn.1, "ASV_ID")

#add taxonomy columns back into ASV table with a Left Join using inner_join function from dplyr
a.bn.T <- a.bn.1 %>% inner_join(t.1, by= "ASV_ID")

#for RA
# save bonney subset as an R file
saveRDS(a.bn.T, paste0(objects2.b.fp, "/asv.wTax.bn.rds"))

#save bonney subset as .txt file 
write.table(a.bn.T, file = paste0(input2.fp, "/ASVtable_16S_wTax_bonney.txt"), 
            sep = "\t", row.names = FALSE, col.names = TRUE)

# Hoare Basin
####################################################################
#keep rows in ASV table with SampleIDs that match Sample IDs in mapping file
a.hr <- subset(a.14, (SampleID %in% m.hr$SampleID )) 

#assign rownames as Sample IDs
rownames(a.hr) <- a.hr$SampleID

#remove SampleID column
a.hr$SampleID <- NULL

#transpose
a.hr.1 <- data.frame(t(a.hr))

#merge ASV table and Taxonomy data frame
#move row names of samples into 1st column as 'SampleID' to match column in taxonomy file
a.hr.1 <- tibble::rownames_to_column(a.hr.1, "ASV_ID")

#add taxonomy columns back into ASV table with a Left Join using inner_join function from dplyr
a.hr.T <- a.hr.1 %>% inner_join(t.1, by= "ASV_ID")

#for RA
# save hoare subset as an R file
saveRDS(a.hr.T, paste0(objects2.h.fp, "/asv.wTax.hr.rds"))

#save hoare subset as .txt file 
write.table(a.hr.T, file = paste0(input2.fp, "/ASVtable_16S_wTax_hoare.txt"), 
            sep = "\t", row.names = FALSE, col.names = TRUE)

# Frxyell Basin
####################################################################
#keep rows in ASV table with SampleIDs that match Sample IDs in mapping file
a.fx <- subset(a.14, (SampleID %in% m.fx$SampleID )) 

#assign rownames as Sample IDs
rownames(a.fx) <- a.fx$SampleID

#remove SampleID column
a.fx$SampleID <- NULL

#transpose
a.fx.1 <- data.frame(t(a.fx))

#merge ASV table and Taxonomy data frame
#move row names of samples into 1st column as 'SampleID' to match column in taxonomy file
a.fx.1 <- tibble::rownames_to_column(a.fx.1, "ASV_ID")

#add taxonomy columns back into ASV table with a Left Join using inner_join function from dplyr
a.fx.T <- a.fx.1 %>% inner_join(t.1, by= "ASV_ID")

#for RA
# save fryxell subset as an R file
saveRDS(a.fx.T, paste0(objects2.f.fp, "/asv.wTax.fx.rds"))

#save fryxell subset as .txt file 
write.table(a.fx.T, file = paste0(input2.fp, "/ASVtable_16S_wTax_fryxell.txt"), 
            sep = "\t", row.names = FALSE, col.names = TRUE)

```