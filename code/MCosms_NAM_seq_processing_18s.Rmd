---
title: "MDV Nutrient Limitation ASV table w/ taxonomy processing - 18S SSU rRNA gene"
author: "Adam Solon"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---

<h1 align = "center" > Seq Table Processing </h1>
&nbsp;  
&nbsp;    

### Script Summary  
This script processes the Amplicon Sequence Variants (ASVs) table output from DADA2. It 

##### Ten steps to running this pipeline:  
1.  Organizing and formatting files
2.  Subsetting according to basin


```{r, echo = FALSE, include = FALSE}
# Change identifiers to your system and file naming. 
user <- "C:/Users/adams" # computer user name
folder <- "/Desktop/projects"
project <- "/MDV_Soils_nutrient_limitation/manuscript1"
analyses <- "/analyses"
data  <- "/dna_seq/amplicons"
analysis1 <- "/seq_processing/18S"
analysis2 <- "/RA_relative_abundance/18S"
ecosystem <- "lab microcosms - Taylor Valley soils" # Define the environment for use in report language.
project.fp <- paste0(user, folder, project)
```

```{r Install and load packages, echo = FALSE, include = FALSE}

# install.packages("tidyverse")
# install.packages("knitr")
# install.packages("kableExtra")
# install.packages("plotly")
# install.packages("stringr")

library(tidyverse); packageVersion("tidyverse")
library(knitr); packageVersion("knitr")
library(kableExtra); packageVersion("kableExtra")
library(plotly); packageVersion("plotly")
library(stringr); packageVersion("stringr")

knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(include = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
```

### Step 1: Organize project directory, input files, and format

The first step to running this pipeline is to organize folders and identify file paths. This keeps everything organized and helps further down the pipeline in retrieving and saving results in a reliable location. 

```{r set paths for project}
# First define the project and project folders. 

# Create project directory
###################################################
project.fp <- paste0(user, folder, project)
if (!dir.exists(project.fp)) dir.create(project.fp)

# Create sub-directory for all analyses for project 
###################################################
analyses.fp <- paste0(project.fp, analyses)
if (!dir.exists(analyses.fp)) dir.create(analyses.fp)

# Create sub-directory for data type 
###################################################
data.fp <- paste0(analyses.fp, data)
if (!dir.exists(data.fp)) dir.create(data.fp)

# Create sub-directory for specific analysis 
###################################################
analysis1.fp <- paste0(data.fp, analysis1)
if (!dir.exists(analysis1.fp)) dir.create(analysis1.fp)

# Create sub-directories for analysis 
###################################################

# Create directory for 'before' pipeline inputs
input.fp <- paste0(analysis1.fp, "/input")
if (!dir.exists(input.fp)) dir.create(input.fp)

# Create directory for 'within' pipeline R objects 
objects.fp <- paste0(analysis1.fp, "/objects")
if (!dir.exists(objects.fp)) dir.create(objects.fp)

# Create directory for 'after' pipeline outputs 
output.fp <- paste0(analysis1.fp, "/output")
if (!dir.exists(output.fp)) dir.create(output.fp)

# Check for the folders here as a sanity check. Should see "Input" and "Objects" if starting from scratch.
list.files(analysis1.fp) 
```

####Create additional sub-directories for additional analyses

```{r}
# Create sub-directory for Relative Abundance (RA) analysis
###################################################
analysis2.fp <- paste0(data.fp, analysis2)
if (!dir.exists(analysis2.fp)) dir.create(analysis2.fp)

# Create sub-directories for RA 
###################################################

# Create directory for 'before' pipeline inputs
input2.fp <- paste0(analysis2.fp, "/input")
if (!dir.exists(input2.fp)) dir.create(input2.fp)

# Create directory for 'within' pipeline R objects 
objects2.fp <- paste0(analysis2.fp, "/objects")
if (!dir.exists(objects2.fp)) dir.create(objects2.fp)

# Create directory for 'after' pipeline outputs 
output2.fp <- paste0(analysis2.fp, "/output")
if (!dir.exists(output2.fp)) dir.create(output2.fp)

# Check for the folders here as a sanity check. Should see "Input" and "Objects" if starting from scratch.
list.files(analysis2.fp) 

```

```{r}
# Create further sub-directories by basin
###################################################

# Create directory for 'within' pipeline R objects 
objects2.b.fp <- paste0(objects2.fp, "/bonney")
if (!dir.exists(objects2.b.fp)) dir.create(objects2.b.fp)

# Create directory for 'after' pipeline outputs 
output2.b.fp <- paste0(output2.fp, "/bonney")
if (!dir.exists(output2.b.fp)) dir.create(output2.b.fp)

# Create sub-directories for Hoare basin 
###################################################

# Create directory for 'within' pipeline R objects 
objects2.h.fp <- paste0(objects2.fp, "/hoare")
if (!dir.exists(objects2.h.fp)) dir.create(objects2.h.fp)

# Create directory for 'after' pipeline outputs 
output2.h.fp <- paste0(output2.fp, "/hoare")
if (!dir.exists(output2.h.fp)) dir.create(output2.h.fp)

# Create sub-directories for Fryxell basin 
###################################################

# Create directory for 'within' pipeline R objects 
objects2.f.fp <- paste0(objects2.fp, "/fryxell")
if (!dir.exists(objects2.f.fp)) dir.create(objects2.f.fp)

# Create directory for 'after' pipeline outputs 
output2.f.fp <- paste0(output2.fp, "/fryxell")
if (!dir.exists(output2.f.fp)) dir.create(output2.f.fp)

```
  
#### Input   
Required input files:   
  
1.  The ASV table from DADA2 pipeline 
2.  The 'mapping file' w/ relevant metadata for each sample

Input files and re-format for use in pipeline

```{r input data files}
# input data files
# ASV Table (from DADA2)
asvTable.fp <- paste0(input.fp, "/MCosms_II_seqtab_wTax_18s.txt") 

# Mapping File (metadata relevant for study samples)
mappingFile.fp <- paste0(input.fp, "/MCosms_II_map_file.txt") 

#input 18s ASV table w/ taxonomy
a <- read.table(asvTable.fp, header = T, sep = "\t")

#input metadata (i.e. mapping file)
m <- read.table(mappingFile.fp, header = T, sep = "\t")
#

```

#### Format
Format files by creating separate 'taxonomy' object and removing 'taxonomy' column from ASV table

```{r format r objects- rename 'ESV_ID' column in ASV table and remove 'taxonomy' from ASV table and create separate taxonomy data frame}

#rename ESV_ID
a <- rename(a, ASV_ID = ESV_ID)

#create data frame of only taxonomy
t <- as.data.frame(a$taxonomy)

#rename column as 'taxonomy'
names(t)[1] <- "taxonomy"

#separate the taxonomic string by the ; separator
t.1 <- str_split_fixed(t$taxonomy, ";", 8)

#rename columns w/ taxonomic ranks for 18S data
colnames(t.1)[1:8] <- c("Domain", "Phylum", "Class", "Order", "Family", "Genus", "Species", "Accession_number")

#save t.1 object as data frame
t.1 <- as.data.frame(t.1)

#ASV IDs as row names
rownames(t.1) <- a$ASV_ID

#move row names of samples into 1st column as 'SampleID' to match 1st column of mapping file
t.1 <- tibble::rownames_to_column(t.1, "ASV_ID")

#remove 'taxonomy' column from ASV table
a$taxonomy <- NULL
```

####Subset samples from MDV nutrient limitation microcosm experiment & blanks
This step retains only the samples from this study out of a larger DADA2 ASV table with samples from multiple studies.

```{r subset target samples}
#subset ASV table
#assign row names from 'ASV_ID' column
rownames(a) <- a$ASV_ID

#remove ESV_ID column
a$ASV_ID <- NULL

#transpose so rows and columns are flipped
a.1 <- as.data.frame(t(a))

#move row names of samples into 1st column as 'SampleID' to match 1st column of mapping file
a.1 <- tibble::rownames_to_column(a.1, "SampleID")

#keep rows in ASV table with SampleIDs that match Sample IDs in mapping file
a.2 <- subset(a.1, (SampleID %in% m$SampleID )) 

#assign samples IDs back as row names
rownames(a.2) <- a.2$SampleID

#remove Sample ID column
a.2$SampleID <- NULL

```

#remove ASVs that are not found in samples (i.e. total sequences = 0)

```{r}
#transpose
a.3 <- as.data.frame(t(a.2))

# create row sum column for ASV total sequences
a.3 <- a.3 %>% mutate(total = rowSums(.))

# re-order with greatest row sum 1st
a.3 <- a.3 %>% arrange(desc(total))

#remove rows (i.e., ASVs) that contain zeros
a.4 <- a.3 %>% filter(total!= 0)

#remove 'total' column
a.4$total <- NULL

```

####Subset blanks to create contaminant list
This step will subset out blank samples to determine if any contaminants were introduced during post-experiment sample processing (e.g., DNA extraction, library prep, sequencing)
1. create a subset mapping file w/ only blanks
2. subset ASV table with only blank SampleIDs
3. Remove any ASVs that register only zeroes
4. Join taxonomy of any remaining ASVs
5. Save as an R object (.Rds) and .txt file

```{r create a data frame with blanks to determine contaminants in other samples}

#subset mapping file with only blanks
m.blanks <- filter(m, treatment == "blank") 

#transpose
a.5 <- as.data.frame(t(a.4))

#move row names of samples into 1st column as 'SampleID' to match 1st column of mapping file
a.5 <- tibble::rownames_to_column(a.5, "SampleID")

#keep rows in ASV table with SampleIDs that match Sample IDs in mapping file
a.blanks <- subset(a.5, (SampleID %in% m.blanks$SampleID )) 

#remove 'SampleID' column
a.blanks$SampleID <- NULL

#transpose
a.blanks.1 <- as.data.frame(t(a.blanks))

# create row sum column for ASV total sequences
a.blanks.1 <- a.blanks.1 %>% mutate(total = rowSums(.))

# re-order with greatest row sum 1st
a.blanks.1 <- a.blanks.1 %>% arrange(desc(total))

#remove rows (i.e., ASVs) that contain zeros
a.blanks.2 <- a.blanks.1 %>% filter(total!= 0)

#move row names of samples into 1st column as 'SampleID' to match column in taxonomy file
a.blanks.2 <- tibble::rownames_to_column(a.blanks.2, "ASV_ID")

#retain ESV_3 and ESV 104 ('planophila') as they are present in decent amount in bonney bulk soils (likely reverse contamination)
a.blanks.2 <- a.blanks.2 %>% filter(ASV_ID != "ESV_3")
a.blanks.2 <- a.blanks.2 %>% filter(ASV_ID != "ESV_104")

#add taxonomy columns back into ASV table with a Left Join using inner_join function from dplyr
a.blanks.T <- a.blanks.2 %>% inner_join(t.1, by= "ASV_ID")

# save as an R file
saveRDS(a.blanks.T, paste0(objects.fp, "/a.blanks.T.rds"))

#save as .txt file
write.table(a.blanks.T, file = paste0(output.fp, "/asvTab_blanks_wTax.txt"), 
            sep = "\t", row.names = TRUE, col.names = NA)

```

####Calculate row sums of ASV table to determine library size of each sample and remove any samples with minimal sequences
1. Subset out only non-blank samples
2. Calculate total sequences in each sample (i.e. library size)
3. Remove any samples with very low sequence count
4. Save as an R object (.Rds) and .txt file

```{r create new column with row sums (i.e. library size of each sample) and reorder rows by descending value}

#keep rows in ASV table with SampleIDs that do NOT match Sample IDs in blanks mapping file
a.6 <- subset(a.5, !(SampleID %in% m.blanks$SampleID )) 

#row names as SampleID column
rownames(a.6) <- a.6$SampleID

#remove 'SampleID' column
a.6$SampleID <- NULL

# create row sum column
a.lib.size <- a.6 %>% mutate(library_size = rowSums(.))

# re-order with greatest row sum 1st
a.lib.size <- a.lib.size %>% arrange(desc(library_size))

#remove any samples with less than 1000 sequences
a.lib.size.1 <- a.lib.size %>% filter(library_size > 1000)

#class data frame 
a.lib.size.2 <- as.data.frame(a.lib.size.1$library_size)

#ASV IDs as row names
rownames(a.lib.size.2) <- rownames(a.lib.size.1)

#rename column as 'taxonomy'
names(a.lib.size.2)[1] <- "Library_Size"

#move row names to 1st column and name 'ASV_ID'
a.lib.size.2 <- tibble::rownames_to_column(a.lib.size.2, "SampleID")

#add row with total sequences of study
a.lib.size.2 <- a.lib.size.2 %>%
            bind_rows(summarise(., across(where(is.numeric), sum),
                                   across(where(is.character), ~'Total')))

# save as an R file
saveRDS(a.lib.size.2, paste0(objects.fp, "/a.lib.size.2.rds"))

#save as .txt file
write.table(a.lib.size.2, file = paste0(output.fp, "/asvTab_library_size.txt"), 
            sep = "\t", row.names = FALSE, col.names = TRUE)

```

# Remove possible blank contaminants 

```{r}

#remove only ASVs from blanks table with sufficient sequence amounts (e.g. 50 sequences)
c <- a.blanks.2 %>% filter(total > 50)

#transpose ASV talbe back to samples as columns and ASVs as rows
a.7 <- as.data.frame(t(a.6))

#move row names of samples into 1st column as 'SampleID' to match column in taxonomy file
a.7 <- tibble::rownames_to_column(a.7, "ASV_ID")

#remove rows with ESVID that matches contaminant column of ESVIS
a.8 <- subset(a.7, !(ASV_ID %in% c$ASV_ID)) 

```

# Remove possible library prep, sequencing, and/or taxonomic assignment misclassification

```{r}
#add taxonomy columns back into ASV table with a Left Join using inner_join function from dplyr
a.8.T <- a.8 %>% inner_join(t.1, by= "ASV_ID")

#remove ASVs that are completely unassigned
a.9 <- a.8.T %>% filter(Domain != c("NA")) 

#remove ASVs that are bacteria (because these are 18S-amplified libraries NOT 16S) 
a.10 <- a.9 %>% filter(Domain != c("Bacteria")) 

#remove ASVs that are archaea (because these are 18S-amplified libraries NOT 16S) 
a.11 <- a.10 %>% filter(Domain != c("Archaea")) 

#remove mitochondria that are identified as alphaproteobacteria
a.12 <- a.11 %>% filter(Family != "Mitochondria")

# save as an R file
saveRDS(a.12, paste0(objects.fp, "/ASV.table.12.wTax.filtered.rds"))

#save as .txt file
write.table(a.12, file = paste0(output.fp, "/asvTab_18S_wTax_filtered.txt"), 
            sep = "\t", row.names = FALSE, col.names = TRUE)

```

####Save filtered ASV table and subset mapping file (i.e. no blanks)
1. Save ASV table w/ taxonomy file
2. Subset mapping file
3. Save mapping file

```{r create new sub-directories for additional analyses}
# save as an R file
saveRDS(a.12, paste0(objects2.fp, "/ASV.table.12.wTax.filtered.rds"))

#save as .txt file
write.table(a.12, file = paste0(input2.fp, "/asvTab_18S_wTax_filtered.txt"), 
            sep = "\t", row.names = FALSE, col.names = TRUE)

#subset mapping file without blanks
m.1 <- filter(m, treatment != "blank") 

# save mapping file subset as an R file
saveRDS(m.1, paste0(objects2.fp, "/m.1.rds"))

#save mapping file subset as .txt file 
write.table(m.1, file = paste0(input2.fp, "/map_file_no_blanks.txt"), 
            sep = "\t", row.names = FALSE, col.names = TRUE)

```

####Re-format ASV table data frame

```{r}

#row names as SampleID column
rownames(a.12) <- a.12$ASV_ID

#remove 'SampleID' column
a.12$ASV_ID <- NULL

#remove taxonomy columns
a.13 <- subset (a.12, select = -c(Domain:Accession_number))

#transpose
a.13 <- data.frame(t(a.13))
```

#recalculate library size post-filtering

```{r}

# create row sum column
a.lib.size.filt <- a.13 %>% mutate(library_size = rowSums(.))

# re-order with greatest row sum 1st
a.lib.size.filt <- a.lib.size.filt %>% arrange(desc(library_size))

#class data frame 
a.lib.size.filt.1 <- as.data.frame(a.lib.size.filt$library_size)

#ASV IDs as row names
rownames(a.lib.size.filt.1) <- rownames(a.lib.size.filt)

#rename column as 'taxonomy'
names(a.lib.size.filt.1)[1] <- "Library_Size_Filtered"

#move row names to 1st column and name 'ASV_ID'
a.lib.size.filt.1 <- tibble::rownames_to_column(a.lib.size.filt.1, "SampleID")

#add row with total sequences of study
a.lib.size.filt.1 <- a.lib.size.filt.1 %>%
            bind_rows(summarise(., across(where(is.numeric), sum),
                                   across(where(is.character), ~'Total')))

# save as an R file
saveRDS(a.lib.size.filt.1, paste0(objects.fp, "/a.lib.size.filt.1.rds"))

#save as .txt file
write.table(a.lib.size.filt.1, file = paste0(output.fp, "/asvTab_library_size_filtered.txt"), 
            sep = "\t", row.names = FALSE, col.names = TRUE)

```

####Create a pre- and post-filtering data frame with new column showing # of reads removed

```{r}
#add taxonomy columns back into ASV table with a Left Join using inner_join function from dplyr
lib.size.final <- a.lib.size.2 %>% inner_join(a.lib.size.filt.1, by= "SampleID")

# create row sum column
lib.size.final.1 <- lib.size.final %>% mutate(filtered = Library_Size - Library_Size_Filtered)

# save as an R file
saveRDS(lib.size.final.1, paste0(objects.fp, "/lib.size.final.1.rds"))

#save as .txt file
write.table(lib.size.final.1, file = paste0(output.fp, "/Library_Size_final.txt"), 
            sep = "\t", row.names = FALSE, col.names = TRUE)

#visualize filtering
#ggplot(lib.size.final.1, aes(x= , y = SampleID)) + geom_point() # w/ blanks: color=Sample_or_Control

#ggplot(lib.size.final.1) +
#  aes(x = filtered, color = , fill = filtered) +
#  geom_density(alpha = 0.25) # add transparency


```

####Subset mapping files by basin for follow-on analyses
1. Subset mapping files by basin
2. Save subset mapping files

```{r}
# Subset by Basin
##################################################################
# Bonney Basin
##################################################################
#subset mapping file- Bonney
m.bn <- filter(m.1, location == "BonneyBasin") 

#for DA
# save bonney subset as an R file
saveRDS(m.bn, paste0(objects2.b.fp, "/m.bn.rds"))

#save bonney subset as .txt file 
write.table(m.bn, file = paste0(input2.fp, "/map_file_bonney.txt"), 
            sep = "\t", row.names = FALSE, col.names = TRUE)

# Hoare Basin
#################################################################
#subset mapping file- Hoare
m.hr <- filter(m.1, location == "HoareBasin") 

#for RA
#save hoare subset as an R file
saveRDS(m.hr, paste0(objects2.h.fp, "/m.hr.rds"))

#save hoare subset as .txt file
write.table(m.hr, file = paste0(input2.fp, "/map_file_hoare.txt"), 
            sep = "\t", row.names = FALSE, col.names = TRUE)

#Fryxell Basin
###################################################################
#subset mapping file- Fryxell 
m.fx <- filter(m.1, location == "FryxellBasin") 

#for RA
#save fryxell subset as an R file
saveRDS(m.fx, paste0(objects2.f.fp, "/m.fx.rds"))

#save fryxell as .txt file
write.table(m.fx, file = paste0(input2.fp, "/map_file_fryxell.txt"), 
            sep = "\t", row.names = FALSE, col.names = TRUE)

```

####Subset ASV tables by basin for follow-on analyses
1. Subset ASV table by basin
2. Save subset ASV tables

```{r}

#move row names of samples into 1st column as 'SampleID' to match 1st column of mapping file
a.14 <- tibble::rownames_to_column(a.13, "SampleID")

# Subset by basin
####################################################################
# Bonney Basin
####################################################################
#keep rows in ASV table with SampleIDs that match Sample IDs in mapping file
a.bn <- subset(a.14, (SampleID %in% m.bn$SampleID )) 

#assign rownames as Sample IDs
rownames(a.bn) <- a.bn$SampleID

#remove SampleID column
a.bn$SampleID <- NULL

#transpose
a.bn.1 <- data.frame(t(a.bn))

#merge ASV table and Taxonomy data frame
#move row names of samples into 1st column as 'SampleID' to match column in taxonomy file
a.bn.1 <- tibble::rownames_to_column(a.bn.1, "ASV_ID")

#add taxonomy columns back into ASV table with a Left Join using inner_join function from dplyr
a.bn.T <- a.bn.1 %>% inner_join(t.1, by= "ASV_ID")

#for DA
# save bonney subset as an R file
saveRDS(a.bn.T, paste0(objects2.b.fp, "/asv.wTax.bn.rds"))

#save bonney subset as .txt file 
write.table(a.bn.T, file = paste0(input2.fp, "/ASVtable_18S_wTax_bonney.txt"), 
            sep = "\t", row.names = FALSE, col.names = TRUE)

# Hoare Basin
####################################################################
#keep rows in ASV table with SampleIDs that match Sample IDs in mapping file
a.hr <- subset(a.14, (SampleID %in% m.hr$SampleID )) 

#assign rownames as Sample IDs
rownames(a.hr) <- a.hr$SampleID

#remove SampleID column
a.hr$SampleID <- NULL

#transpose
a.hr.1 <- data.frame(t(a.hr))

#merge ASV table and Taxonomy data frame
#move row names of samples into 1st column as 'SampleID' to match column in taxonomy file
a.hr.1 <- tibble::rownames_to_column(a.hr.1, "ASV_ID")

#add taxonomy columns back into ASV table with a Left Join using inner_join function from dplyr
a.hr.T <- a.hr.1 %>% inner_join(t.1, by= "ASV_ID")

#for DA
# save hoare subset as an R file
saveRDS(a.hr.T, paste0(objects2.h.fp, "/asv.wTax.hr.rds"))

#save hoare subset as .txt file 
write.table(a.hr.T, file = paste0(input2.fp, "/ASVtable_18S_wTax_hoare.txt"), 
            sep = "\t", row.names = FALSE, col.names = TRUE)

# Frxyell Basin
####################################################################
#keep rows in ASV table with SampleIDs that match Sample IDs in mapping file
a.fx <- subset(a.14, (SampleID %in% m.fx$SampleID )) 

#assign rownames as Sample IDs
rownames(a.fx) <- a.fx$SampleID

#remove SampleID column
a.fx$SampleID <- NULL

#transpose
a.fx.1 <- data.frame(t(a.fx))

#merge ASV table and Taxonomy data frame
#move row names of samples into 1st column as 'SampleID' to match column in taxonomy file
a.fx.1 <- tibble::rownames_to_column(a.fx.1, "ASV_ID")

#add taxonomy columns back into ASV table with a Left Join using inner_join function from dplyr
a.fx.T <- a.fx.1 %>% inner_join(t.1, by= "ASV_ID")

#for RA
# save fryxell subset as an R file
saveRDS(a.fx.T, paste0(objects2.f.fp, "/asv.wTax.fx.rds"))

#save fryxell subset as .txt file 
write.table(a.fx.T, file = paste0(input2.fp, "/ASVtable_18S_wTax_fryxell.txt"), 
            sep = "\t", row.names = FALSE, col.names = TRUE)

```

